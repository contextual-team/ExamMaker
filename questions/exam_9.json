{"pageProps":{"questions":[{"id":"PZlb7fjNTFE8VsSpGTUj","answer_images":[],"timestamp":"2023-10-28 19:45:00","isMC":true,"question_images":[],"discussion":[{"timestamp":"1701968100.0","comment_id":"1090000","upvote_count":"2","poster":"xhilmi","content":"Selected Answer: A\nChoose Ooption A:\nConfigure Binary Authorization in your GKE clusters to enforce deploy-time security policies. \n\nBinary Authorization allows you to define and enforce policies that determine which container images can be deployed based on image signatures. By configuring Binary Authorization, you can enforce deploy-time security policies, ensuring that only trusted and verified container images are allowed to run in your GKE clusters.\n\nThis approach provides a robust security mechanism without requiring additional custom validators or complex configurations, minimizing management overhead while meeting the stringent security requirements of a highly regulated domain."},{"poster":"mshafa","comment_id":"1061278","timestamp":"1699006380.0","content":"A is the answer.","upvote_count":"2"},{"comment_id":"1059599","timestamp":"1698835380.0","upvote_count":"2","content":"Selected Answer: A\nusing binary-authorization","poster":"lelele2023"},{"comment_id":"1056361","poster":"koo_kai","timestamp":"1698515100.0","upvote_count":"3","content":"Selected Answer: A\nhttps://cloud.google.com/binary-authorization/docs/overview"}],"answers_community":["A (100%)"],"unix_timestamp":1698515100,"question_text":"","answer":"A","question_id":41,"choices":{"D":"Configure Kritis to run in your GKE clusters to enforce deploy-time security policies.","C":"Use Cloud Run to write and deploy a custom validator. Enable an Eventarc trigger to perform validations when new images are uploaded.","B":"Grant the roles/artifactregistry.writer role to the Cloud Build service account. Confirm that no employee has Artifact Registry write permission.","A":"Configure Binary Authorization in your GKE clusters to enforce deploy-time security policies."},"topic":"1","answer_ET":"A","answer_description":"","url":"https://www.examtopics.com/discussions/google/view/124848-exam-professional-cloud-devops-engineer-topic-1-question-135/","exam_id":5},{"id":"nXoRDmw0SvtvwrMTYOPv","answer_ET":"AC","topic":"1","exam_id":5,"isMC":true,"unix_timestamp":1697907300,"question_id":42,"answer_images":[],"answer_description":"","question_text":"","answers_community":["CE (86%)","14%"],"answer":"CE","timestamp":"2023-10-21 18:55:00","discussion":[{"poster":"activist","timestamp":"1697907300.0","upvote_count":"8","comments":[{"content":"Me too\nE -> include all incident participants in postmortem authoring, no much sense, the incident commander is the author of the postmortem\nA -> identify the person or team responsible for causing the incident\nC -> without naming internal system components, the postmortem has to be focus on the processes/components","comment_id":"1104541","poster":"Feliphus","timestamp":"1703413380.0","upvote_count":"1"}],"comment_id":"1049681","content":"I think the answers are B & D."},{"content":"Selected Answer: CE\nOption B is incorrect because it states that the postmortem should include how the incident could have been worse.The focus of the postmortem should be on identifying the root cause of the incident and developing recommendations for preventing future occurrences.","poster":"mshafa","timestamp":"1699050720.0","upvote_count":"6","comment_id":"1061806"},{"timestamp":"1708077240.0","comment_id":"1151874","poster":"alpha_canary","content":"Selected Answer: CE\nC: https://sre.google/workbook/postmortem-culture/#:~:text=away%20from%20us%E2%80%9D).-,Preventative%20action,Disallow%20any%20single%20operation%20from%20affecting%20servers%20spanning%20namespace/class%20boundaries%E2%80%9D).,-Blamelessness\n\nE: https://sre.google/workbook/postmortem-culture/#:~:text=Include%20all%20incident%20participants%20in%20postmortem%20authoring\nhttps://sre.google/workbook/postmortem-culture/#:~:text=In%20order%20to%20maintain%20a%20healthy%20postmortem%20culture%20within%20an%20organization%2C%20it%E2%80%99s%20important%20to%20share%20postmortems%20as%20widely%20as%20possible","upvote_count":"1"},{"upvote_count":"3","comment_id":"1090009","poster":"xhilmi","content":"Selected Answer: CE\nChoose C & E\n\nOption C emphasizes including the severity of the incident, prevention strategies for future occurrences, and an analysis of what caused the incident without necessarily naming internal system components. This approach ensures a balance between transparency and security, providing valuable insights without exposing sensitive internal details.\n\nOption E, which advocates involving all incident participants in postmortem authoring and sharing postmortems widely, promotes a collaborative and inclusive culture. Involving all relevant stakeholders ensures a comprehensive understanding of the incident, and sharing postmortems widely fosters transparency, enabling the organization to learn from incidents collectively.\n\nTogether, these practices contribute to a successful postmortem policy that promotes continuous improvement and a culture of learning from incidents.","timestamp":"1701932340.0"},{"comment_id":"1086699","content":"Selected Answer: CE\nVote CE","upvote_count":"2","poster":"nqthien041292","timestamp":"1701593940.0"},{"upvote_count":"2","comment_id":"1081970","content":"Selected Answer: CE\nI'll go for C & E","poster":"bhunias","timestamp":"1701121740.0"},{"timestamp":"1700074260.0","poster":"pharao89","content":"Selected Answer: CE\nA. We don't blame\nB. I can't imagine a postmortem with information on how the incident could have been worse.\nC. Correct answer.\nD. It's nearly the same as C but doesn't include recommendations for the future, so I go with C.\nE. Correct, include all participants of the incident in authoring postmortem to not miss something important.","comment_id":"1071796","upvote_count":"4"},{"poster":"TereRolon","upvote_count":"3","timestamp":"1700008980.0","comment_id":"1070978","content":"I thing is CE \nhttps://sre.google/workbook/postmortem-culture/"},{"comment_id":"1059610","content":"Selected Answer: BD\nShouldn't mention customer information, it's not useful to spread it widely, might be causing negative impact.","timestamp":"1698835860.0","poster":"lelele2023","upvote_count":"3"},{"comment_id":"1056153","content":"B & D is the answer","poster":"khoukha","upvote_count":"4","timestamp":"1698493260.0"},{"poster":"Jason_Cloud_at","comment_id":"1054701","timestamp":"1698333840.0","upvote_count":"1","content":"I would go with B & C"}],"url":"https://www.examtopics.com/discussions/google/view/124238-exam-professional-cloud-devops-engineer-topic-1-question-136/","question_images":[],"choices":{"E":"Ensure that all postmortems include all incident participants in postmortem authoring and share postmortems as widely as possible.","A":"Ensure that all postmortems include what caused the incident, identify the person or team responsible for causing the incident, and how to prevent a future occurrence of the incident.","C":"Ensure that all postmortems include the severity of the incident, how to prevent a future occurrence of the incident, and what caused the incident without naming internal system components.","B":"Ensure that all postmortems include what caused the incident, how the incident could have been worse, and how to prevent a future occurrence of the incident.","D":"Ensure that all postmortems include how the incident was resolved and what caused the incident without naming customer information."}},{"id":"VNGZiDBaODStvSLpwUqb","answer_ET":"A","isMC":true,"question_text":"","question_id":43,"timestamp":"2023-10-22 20:47:00","url":"https://www.examtopics.com/discussions/google/view/124375-exam-professional-cloud-devops-engineer-topic-1-question-137/","unix_timestamp":1698000420,"answer":"D","topic":"1","choices":{"A":"Use a Jenkins server for CI/CD pipelines. Periodically run all tests in the feature branch.","D":"Use Cloud Build to run tests in a specific folder. Trigger Cloud Build for every GitHub pull request.","B":"Ask the pull request reviewers to run the integration tests before approving the code.","C":"Use Cloud Build to run the tests. Trigger all tests to run after a pull request is merged."},"discussion":[{"comment_id":"1090013","content":"Selected Answer: D\nChoose option D\nUse Cloud Build to run tests in a specific folder and trigger Cloud Build for every GitHub pull request.\n\nBy configuring Cloud Build to run tests in a specific folder, you can focus on the relevant tests for the modified code in the feature branch. Triggering Cloud Build for every GitHub pull request ensures that tests are automatically executed whenever changes are proposed, providing continuous integration.\n\nThis approach allows for automated testing of each pull request, providing early feedback to developers and ensuring that changes are thoroughly tested before being merged, contributing to a more reliable and efficient development process.","poster":"xhilmi","upvote_count":"1","timestamp":"1701932760.0"},{"comment_id":"1071798","content":"Selected Answer: D\nD is what I do at work for this scenario and it works well.","poster":"pharao89","timestamp":"1700074440.0","upvote_count":"1"},{"comment_id":"1068396","upvote_count":"2","poster":"mshafa","timestamp":"1699781400.0","content":"Selected Answer: D\nThis approach automates the testing process, integrates well with your existing tools (GitHub and GCP), and ensures that code is tested in the most relevant part of the development lifecycle - before merging into the main branch."},{"poster":"lelele2023","timestamp":"1698836400.0","upvote_count":"1","content":"Selected Answer: D\nshouldn't be C since it makes the test to happen after merge. Answer is D - as soon as a PR gets created then it runs tests.","comment_id":"1059617"},{"poster":"koo_kai","upvote_count":"2","content":"Selected Answer: D\nall code is tested before changes are accepted","comment_id":"1056364","timestamp":"1698515460.0"},{"comment_id":"1054708","poster":"Jason_Cloud_at","content":"Selected Answer: C\nI would go with C","upvote_count":"2","timestamp":"1698334020.0"},{"content":"Wouldnt it be D considering you would want to run the tests when the PR is created and not after the code is already merged","upvote_count":"3","timestamp":"1698084060.0","poster":"Jay09812","comment_id":"1052142"},{"comment_id":"1050983","poster":"activist","upvote_count":"2","timestamp":"1698000420.0","comments":[],"content":"Answer C is correct. \nhttps://cloud.google.com/build/docs/automating-builds/create-manage-triggers"}],"answers_community":["D (78%)","C (22%)"],"answer_description":"","question_images":[],"exam_id":5,"answer_images":[]},{"id":"lBh82pjy6SGy00p8J6NC","question_images":[],"choices":{"B":"Install a continuous profiling tool into Compute Engine. Configure the application to send profiling data to the tool.","C":"Periodically run the go tool pprof command against the application instance. Analyze the results by using flame graphs.","A":"Use Cloud Monitoring to assess the App Engine CPU utilization metric.","D":"Configure Cloud Profiler, and initialize the cloud.google.com/go/profiler library in the application."},"topic":"1","timestamp":"2023-10-28 13:57:00","exam_id":5,"answer_ET":"D","answer":"D","answer_description":"","answer_images":[],"discussion":[{"comment_id":"1056162","poster":"khoukha","upvote_count":"7","timestamp":"1698494220.0","content":"answer is D:\nhttps://cloud.google.com/profiler/docs/profiling-go#app-engine"},{"content":"Selected Answer: D\nChoose option D\n\nConfigure Cloud Profiler and initialize the cloud.google.com/go/profiler library in the application. Cloud Profiler is designed for low-overhead continuous profiling in production environments.\n\nBy configuring Cloud Profiler and initializing the corresponding library in the Go application, you can collect detailed performance data without significantly impacting the application's performance.\n\nThis approach allows you to analyze profiling information, identify slow paths in the code, and gain insights into performance bottlenecks, providing a powerful and efficient way to troubleshoot and optimize the application in a production environment.","comment_id":"1090014","poster":"xhilmi","upvote_count":"2","timestamp":"1701933180.0"},{"timestamp":"1699781520.0","upvote_count":"2","content":"Selected Answer: D\nD is the answer.","comment_id":"1068398","poster":"mshafa"},{"content":"Selected Answer: D\n// appengine is an example of starting cloud.google.com/go/profiler on\n// App Engine.\npackage main\n\nimport (\n \"cloud.google.com/go/profiler\"\n)","comment_id":"1059626","timestamp":"1698836940.0","upvote_count":"2","poster":"lelele2023"}],"url":"https://www.examtopics.com/discussions/google/view/124814-exam-professional-cloud-devops-engineer-topic-1-question-138/","isMC":true,"question_id":44,"question_text":"","unix_timestamp":1698494220,"answers_community":["D (100%)"]},{"id":"0m1lJyVwkJoRfg8zmPop","answer_ET":"C","isMC":true,"exam_id":5,"unix_timestamp":1698334500,"timestamp":"2023-10-26 17:35:00","answers_community":["D (78%)","A (22%)"],"topic":"1","question_text":"","answer":"D","answer_images":[],"answer_description":"","url":"https://www.examtopics.com/discussions/google/view/124674-exam-professional-cloud-devops-engineer-topic-1-question-139/","discussion":[{"timestamp":"1710690000.0","upvote_count":"2","poster":"asdasdfczxhjkvz","comment_id":"1175923","content":"Selected Answer: A\nA is correct"},{"comments":[{"poster":"Luu13","upvote_count":"1","content":"If the filter in the exclusion filter is for severity >= DEBUG... would not exclude severity >= DEBUG instead of severity <= DEBUG?","comment_id":"1204394","timestamp":"1714462140.0"}],"poster":"xhilmi","comment_id":"1090017","content":"Selected Answer: D\nTo minimize costs associated with application logging in Google Kubernetes Engine (GKE) while still collecting operational logs, the recommended approach is (option D).\n\nAdd the severity >= DEBUG resource.type = \"k8s_container\" exclusion filter to the _Default logging sink in the project associated with the development environment.\n\nThis filter excludes logs with a severity level of DEBUG or lower for the specified resource type, \"k8s_container,\" effectively reducing the volume of verbose application logs being ingested into Cloud Logging.\n\nThis allows you to focus on collecting GKE operational logs while excluding less critical and potentially costly application logs. It helps strike a balance between maintaining visibility into operational aspects and optimizing costs associated with log storage and processing.","upvote_count":"1","timestamp":"1701933420.0"},{"comments":[{"poster":"lelele2023","comment_id":"1059636","upvote_count":"1","timestamp":"1698837600.0","content":"C is invalid since a valid gcloud CLI will be: gcloud logging settings update --folder=FOLDER_ID--disable-default-sink\nhttps://cloud.google.com/logging/docs/default-settings#disable-default-sink"}],"content":"Selected Answer: D\nD The idea is to prevent/minimize container logs from getting sent to the sink,","upvote_count":"2","comment_id":"1059632","timestamp":"1698837240.0","poster":"lelele2023"},{"timestamp":"1698334500.0","poster":"Jason_Cloud_at","upvote_count":"4","comment_id":"1054712","content":"Selected Answer: D\nright answer"}],"question_id":45,"question_images":[],"choices":{"C":"Run the gcloud logging sinks update _Default --disabled command in the project associated with the development environment.","A":"Run the gcloud container clusters update --logging=SYSTEM command for the development cluster.","B":"Run the gcloud container clusters update --logging=WORKLOAD command for the development cluster.","D":"Add the severity >= DEBUG resource.type = \"k8s_container\" exclusion filter to the _Default logging sink in the project associated with the development environment."}}],"exam":{"numberOfQuestions":166,"isMCOnly":true,"isImplemented":true,"provider":"Google","lastUpdated":"1 May 2024","id":5,"isBeta":false,"name":"Professional Cloud DevOps Engineer"},"currentPage":9},"__N_SSP":true}